<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta content="Apache Forrest" name="Generator">
<meta name="Forrest-version" content="0.8">
<meta name="Forrest-skin-name" content="pelt">
<title>Fair Scheduler Guide</title>
<link type="text/css" href="skin/basic.css" rel="stylesheet">
<link media="screen" type="text/css" href="skin/screen.css" rel="stylesheet">
<link media="print" type="text/css" href="skin/print.css" rel="stylesheet">
<link type="text/css" href="skin/profile.css" rel="stylesheet">
<script src="skin/getBlank.js" language="javascript" type="text/javascript"></script><script src="skin/getMenu.js" language="javascript" type="text/javascript"></script><script src="skin/fontsize.js" language="javascript" type="text/javascript"></script>
<link rel="shortcut icon" href="images/favicon.ico">
</head>
<body onload="init()">
<script type="text/javascript">ndeSetTextSize();</script>
<div id="top">
<!--+
    |breadtrail
    +-->
<div class="breadtrail">
<a href="http://www.apache.org/">Apache</a> &gt; <a href="http://hadoop.apache.org/">Hadoop</a> &gt; <a href="http://hadoop.apache.org/core/">Core</a><script src="skin/breadcrumbs.js" language="JavaScript" type="text/javascript"></script>
</div>
<!--+
    |header
    +-->
<div class="header">
<!--+
    |start group logo
    +-->
<div class="grouplogo">
<a href="http://hadoop.apache.org/"><img class="logoImage" alt="Hadoop" src="images/hadoop-logo.jpg" title="Apache Hadoop"></a>
</div>
<!--+
    |end group logo
    +-->
<!--+
    |start Project Logo
    +-->
<div class="projectlogo">
<a href="http://hadoop.apache.org/core/"><img class="logoImage" alt="Hadoop" src="images/hadoop-logo-2.gif" title="Scalable Computing Platform"></a>
</div>
<!--+
    |end Project Logo
    +-->
<!--+
    |start Search
    +-->
<div class="searchbox">
<form action="http://www.google.com/search" method="get" class="roundtopsmall">
<input value="hadoop.apache.org" name="sitesearch" type="hidden"><input onFocus="getBlank (this, 'Search the site with google');" size="25" name="q" id="query" type="text" value="Search the site with google">&nbsp; 
                    <input name="Search" value="Search" type="submit">
</form>
</div>
<!--+
    |end search
    +-->
<!--+
    |start Tabs
    +-->
<ul id="tabs">
<li>
<a class="unselected" href="http://hadoop.apache.org/core/">Project</a>
</li>
<li>
<a class="unselected" href="http://wiki.apache.org/hadoop">Wiki</a>
</li>
<li class="current">
<a class="selected" href="index.html">Hadoop 0.20.204.0 Documentation</a>
</li>
</ul>
<!--+
    |end Tabs
    +-->
</div>
</div>
<div id="main">
<div id="publishedStrip">
<!--+
    |start Subtabs
    +-->
<div id="level2tabs"></div>
<!--+
    |end Endtabs
    +-->
<script type="text/javascript"><!--
document.write("Last Published: " + document.lastModified);
//  --></script>
</div>
<!--+
    |breadtrail
    +-->
<div class="breadtrail">

             &nbsp;
           </div>
<!--+
    |start Menu, mainarea
    +-->
<!--+
    |start Menu
    +-->
<div id="menu">
<div onclick="SwitchMenu('menu_1.1', 'skin/')" id="menu_1.1Title" class="menutitle">Getting Started</div>
<div id="menu_1.1" class="menuitemgroup">
<div class="menuitem">
<a href="index.html">Overview</a>
</div>
<div class="menuitem">
<a href="single_node_setup.html">Single Node Setup</a>
</div>
<div class="menuitem">
<a href="cluster_setup.html">Cluster Setup</a>
</div>
</div>
<div onclick="SwitchMenu('menu_selected_1.2', 'skin/')" id="menu_selected_1.2Title" class="menutitle" style="background-image: url('skin/images/chapter_open.gif');">MapReduce</div>
<div id="menu_selected_1.2" class="selectedmenuitemgroup" style="display: block;">
<div class="menuitem">
<a href="mapred_tutorial.html">MapReduce Tutorial</a>
</div>
<div class="menuitem">
<a href="streaming.html">Hadoop Streaming</a>
</div>
<div class="menuitem">
<a href="commands_manual.html">Hadoop Commands</a>
</div>
<div class="menuitem">
<a href="distcp.html">DistCp</a>
</div>
<div class="menuitem">
<a href="vaidya.html">Vaidya</a>
</div>
<div class="menuitem">
<a href="hadoop_archives.html">Hadoop Archives</a>
</div>
<div class="menuitem">
<a href="gridmix.html">Gridmix</a>
</div>
<div class="menuitem">
<a href="capacity_scheduler.html">Capacity Scheduler</a>
</div>
<div class="menupage">
<div class="menupagetitle">Fair Scheduler</div>
</div>
<div class="menuitem">
<a href="hod_scheduler.html">Hod Scheduler</a>
</div>
</div>
<div onclick="SwitchMenu('menu_1.3', 'skin/')" id="menu_1.3Title" class="menutitle">HDFS</div>
<div id="menu_1.3" class="menuitemgroup">
<div class="menuitem">
<a href="hdfs_user_guide.html">HDFS Users </a>
</div>
<div class="menuitem">
<a href="hdfs_design.html">HDFS Architecture</a>
</div>
<div class="menuitem">
<a href="hdfs_permissions_guide.html">Permissions</a>
</div>
<div class="menuitem">
<a href="hdfs_quota_admin_guide.html">Quotas</a>
</div>
<div class="menuitem">
<a href="SLG_user_guide.html">Synthetic Load Generator</a>
</div>
<div class="menuitem">
<a href="libhdfs.html">C API libhdfs</a>
</div>
</div>
<div onclick="SwitchMenu('menu_1.4', 'skin/')" id="menu_1.4Title" class="menutitle">Common</div>
<div id="menu_1.4" class="menuitemgroup">
<div class="menuitem">
<a href="deployment_layout.html">Deployment Layout</a>
</div>
<div class="menuitem">
<a href="file_system_shell.html">File System Shell</a>
</div>
<div class="menuitem">
<a href="service_level_auth.html">Service Level Authorization</a>
</div>
<div class="menuitem">
<a href="native_libraries.html">Native Libraries</a>
</div>
</div>
<div onclick="SwitchMenu('menu_1.5', 'skin/')" id="menu_1.5Title" class="menutitle">Miscellaneous</div>
<div id="menu_1.5" class="menuitemgroup">
<div class="menuitem">
<a href="Secure_Impersonation.html">Secure Impersonation</a>
</div>
<div class="menuitem">
<a href="api/index.html">API Docs</a>
</div>
<div class="menuitem">
<a href="jdiff/changes.html">API Changes</a>
</div>
<div class="menuitem">
<a href="http://wiki.apache.org/hadoop/">Wiki</a>
</div>
<div class="menuitem">
<a href="http://wiki.apache.org/hadoop/FAQ">FAQ</a>
</div>
<div class="menuitem">
<a href="releasenotes.html">Release Notes</a>
</div>
<div class="menuitem">
<a href="changes.html">Change Log</a>
</div>
</div>
<div id="credit"></div>
<div id="roundbottom">
<img style="display: none" class="corner" height="15" width="15" alt="" src="skin/images/rc-b-l-15-1body-2menu-3menu.png"></div>
<!--+
  |alternative credits
  +-->
<div id="credit2"></div>
</div>
<!--+
    |end Menu
    +-->
<!--+
    |start content
    +-->
<div id="content">
<div title="Portable Document Format" class="pdflink">
<a class="dida" href="fair_scheduler.pdf"><img alt="PDF -icon" src="skin/images/pdfdoc.gif" class="skin"><br>
        PDF</a>
</div>
<h1>Fair Scheduler Guide</h1>
<div id="minitoc-area">
<ul class="minitoc">
<li>
<a href="#Purpose">Purpose</a>
</li>
<li>
<a href="#Introduction">Introduction</a>
</li>
<li>
<a href="#Installation">Installation</a>
</li>
<li>
<a href="#Configuring+the+Fair+scheduler">Configuring the Fair scheduler</a>
</li>
<li>
<a href="#Administration"> Administration</a>
</li>
<li>
<a href="#Implementation">Implementation</a>
</li>
</ul>
</div>

    
<a name="N1000D"></a><a name="Purpose"></a>
<h2 class="h3">Purpose</h2>
<div class="section">
<p>This document describes the Fair Scheduler, a pluggable
        MapReduce scheduler for Hadoop which provides a way to share
        large clusters.</p>
</div>

    
<a name="N10017"></a><a name="Introduction"></a>
<h2 class="h3">Introduction</h2>
<div class="section">
<p>Fair scheduling is a method of assigning resources to jobs
        such that all jobs get, on average, an equal share of resources
        over time. When there is a single job running, that job uses the
        entire cluster. When other jobs are submitted, tasks slots that
        free up are assigned to the new jobs, so that each job gets
        roughly the same amount of CPU time. Unlike the default Hadoop
        scheduler, which forms a queue of jobs, this lets short jobs finish
        in reasonable time while not starving long jobs. It is also a 
        reasonable way to share a cluster between a number of users. Finally, 
        fair sharing can also work with job priorities - the priorities are
        used as weights to determine the fraction of total compute time that
        each job should get.
      </p>
<p>
        The scheduler actually organizes jobs further into "pools", and 
        shares resources fairly between these pools. By default, there is a 
        separate pool for each user, so that each user gets the same share 
        of the cluster no matter how many jobs they submit. However, it is 
        also possible to set a job's pool based on the user's Unix group or
        any other jobconf property, such as the queue name property used by 
        <a href="capacity_scheduler.html">Capacity Scheduler</a>. 
        Within each pool, fair sharing is used to share capacity between 
        the running jobs. Pools can also be given weights to share the 
        cluster non-proportionally in the config file.
      </p>
<p>
        In addition to providing fair sharing, the Fair Scheduler allows
        assigning guaranteed minimum shares to pools, which is useful for
        ensuring that certain users, groups or production applications
        always get sufficient resources. When a pool contains jobs, it gets
        at least its minimum share, but when the pool does not need its full
        guaranteed share, the excess is split between other running jobs.
        This lets the scheduler guarantee capacity for pools while utilizing
        resources efficiently when these pools don't contain jobs.       
      </p>
<p>
        The Fair Scheduler lets all jobs run by default, but it is also
        possible to limit the number of running jobs per user and per pool
        through the config file. This can be useful when a user must submit
        hundreds of jobs at once, or in general to improve performance if
        running too many jobs at once would cause too much intermediate data
        to be created or too much context-switching. Limiting the jobs does
        not cause any subsequently submitted jobs to fail, only to wait in the
        sheduler's queue until some of the user's earlier jobs finish. Jobs to
        run from each user/pool are chosen in order of priority and then
        submit time, as in the default FIFO scheduler in Hadoop.
      </p>
<p>
        Finally, the fair scheduler provides several extension points where
        the basic functionality can be extended. For example, the weight
        calculation can be modified to give a priority boost to new jobs,
        implementing a "shortest job first" policy which reduces response
        times for interactive jobs even further.
      </p>
</div>

    
<a name="N10031"></a><a name="Installation"></a>
<h2 class="h3">Installation</h2>
<div class="section">
<p>
        To run the fair scheduler in your Hadoop installation, you need to put
        it on the CLASSPATH. The easiest way is to copy the 
        <em>hadoop-fairscheduler-*.jar</em> from
        <em>HADOOP_HOME/contrib/fairscheduler</em> to <em>HADOOP_HOME/lib</em>.
        Alternatively you can modify <em>HADOOP_CLASSPATH</em> to include this jar, in
        <em>HADOOP_CONF_DIR/hadoop-env.sh</em>
      
</p>
<p>
        In order to compile fair scheduler, from sources execute <em> ant 
        package</em> in source folder and copy the 
        <em>build/contrib/fair-scheduler/hadoop-fairscheduler-*.jar</em> 
        to <em>HADOOP_HOME/lib</em>
      
</p>
<p>
       You will also need to set the following property in the Hadoop config 
       file  <em>HADOOP_CONF_DIR/mapred-site.xml</em> to have Hadoop use 
       the fair scheduler: <br>
       
<span class="codefrag">&lt;property&gt;</span>
<br> 
       
<span class="codefrag">&nbsp;&nbsp;&lt;name&gt;mapred.jobtracker.taskScheduler&lt;/name&gt;</span>
<br>
       
<span class="codefrag">&nbsp;&nbsp;&lt;value&gt;org.apache.hadoop.mapred.FairScheduler&lt;/value&gt;</span>
<br>
       
<span class="codefrag">&lt;/property&gt;</span>
      
</p>
<p>
        Once you restart the cluster, you can check that the fair scheduler 
        is running by going to http://&lt;jobtracker URL&gt;/scheduler 
        on the JobTracker's web UI. A "job scheduler administration" page should 
        be visible there. This page is described in the Administration section.
      </p>
</div>
    
    
<a name="N10070"></a><a name="Configuring+the+Fair+scheduler"></a>
<h2 class="h3">Configuring the Fair scheduler</h2>
<div class="section">
<p>
      The following properties can be set in mapred-site.xml to configure 
      the fair scheduler:
      </p>
<table class="ForrestTable" cellspacing="1" cellpadding="4">
        
<tr>
        
<th colspan="1" rowspan="1">Name</th><th colspan="1" rowspan="1">Description</th>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.allocation.file
        </td>
        <td colspan="1" rowspan="1">
          Specifies an absolute path to an XML file which contains the 
          allocations for each pool, as well as the per-pool and per-user 
          limits on number of running jobs. If this property is not 
          provided, allocations are not used.<br>
          This file must be in XML format, and can contain three types of 
          elements:
          <ul>
          
<li>pool elements, which may contain elements for minMaps, 
          minReduces, maxRunningJobs (limit the number of jobs from the 
          pool to run at once),and weight (to share the cluster 
          non-proportionally with other pools).
          </li>
          
<li>user elements, which may contain a maxRunningJobs to limit 
          jobs. Note that by default, there is a separate pool for each 
          user, so these may not be necessary; they are useful, however, 
          if you create a pool per user group or manually assign jobs 
          to pools.</li>
          
<li>A userMaxJobsDefault element, which sets the default running 
          job limit for any users whose limit is not specified.</li>
          
</ul>
          
<br>
          Example Allocation file is listed below :<br>
          
<span class="codefrag">&lt;?xml version="1.0"?&gt; </span> 
<br>
          
<span class="codefrag">&lt;allocations&gt;</span> 
<br> 
          
<span class="codefrag">&nbsp;&nbsp;&lt;pool name="sample_pool"&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&nbsp;&nbsp;&lt;minMaps&gt;5&lt;/minMaps&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&nbsp;&nbsp;&lt;minReduces&gt;5&lt;/minReduces&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&nbsp;&nbsp;&lt;weight&gt;2.0&lt;/weight&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&lt;/pool&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&lt;user name="sample_user"&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&nbsp;&nbsp;&lt;maxRunningJobs&gt;6&lt;/maxRunningJobs&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&lt;/user&gt;</span>
<br>
          
<span class="codefrag">&nbsp;&nbsp;&lt;userMaxJobsDefault&gt;3&lt;/userMaxJobsDefault&gt;</span>
<br>
          
<span class="codefrag">&lt;/allocations&gt;</span>
          
<br>
          This example creates a pool sample_pool with a guarantee of 5 map 
          slots and 5 reduce slots. The pool also has a weight of 2.0, meaning 
          it has a 2x higher share of the cluster than other pools (the default 
          weight is 1). Finally, the example limits the number of running jobs 
          per user to 3, except for sample_user, who can run 6 jobs concurrently. 
          Any pool not defined in the allocations file will have no guaranteed 
          capacity and a weight of 1.0. Also, any pool or user with no max 
          running jobs set in the file will be allowed to run an unlimited 
          number of jobs.
        </td>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.assignmultiple
        </td>
        <td colspan="1" rowspan="1">
          Allows the scheduler to assign both a map task and a reduce task 
          on each heartbeat, which improves cluster throughput when there 
          are many small tasks to run. Boolean value, default: false.
        </td>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.sizebasedweight
        </td>
        <td colspan="1" rowspan="1">
          Take into account job sizes in calculating their weights for fair 
          sharing.By default, weights are only based on job priorities. 
          Setting this flag to true will make them based on the size of the 
          job (number of tasks needed) as well,though not linearly 
          (the weight will be proportional to the log of the number of tasks 
          needed). This lets larger jobs get larger fair shares while still 
          providing enough of a share to small jobs to let them finish fast. 
          Boolean value, default: false.
        </td>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.poolnameproperty
        </td>
        <td colspan="1" rowspan="1">
          Specify which jobconf property is used to determine the pool that a
          job belongs in. String, default: user.name (i.e. one pool for each 
          user). Some other useful values to set this to are: <br>
          
<ul> 
            
<li> group.name (to create a pool per Unix group).</li>
            
<li>mapred.job.queue.name (the same property as the queue name in 
            <a href="capacity_scheduler.html">Capacity Scheduler</a>).</li>
          
</ul>
        
</td>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.weightadjuster
        </td>
        <td colspan="1" rowspan="1">
        An extensibility point that lets you specify a class to adjust the 
        weights of running jobs. This class should implement the 
        <em>WeightAdjuster</em> interface. There is currently one example 
        implementation - <em>NewJobWeightBooster</em>, which increases the 
        weight of jobs for the first 5 minutes of their lifetime to let 
        short jobs finish faster. To use it, set the weightadjuster 
        property to the full class name, 
        <span class="codefrag">org.apache.hadoop.mapred.NewJobWeightBooster</span> 
        NewJobWeightBooster itself provides two parameters for setting the 
        duration and boost factor. <br>
        
<ol>
        
<li> 
<em>mapred.newjobweightbooster.factor</em>
          Factor by which new jobs weight should be boosted. Default is 3</li>
        
<li>
<em>mapred.newjobweightbooster.duration</em>
          Duration in milliseconds, default 300000 for 5 minutes</li>
        
</ol>
        
</td>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.loadmanager
        </td>
        <td colspan="1" rowspan="1">
          An extensibility point that lets you specify a class that determines 
          how many maps and reduces can run on a given TaskTracker. This class 
          should implement the LoadManager interface. By default the task caps 
          in the Hadoop config file are used, but this option could be used to 
          make the load based on available memory and CPU utilization for example.
        </td>
        
</tr>
        
<tr>
        
<td colspan="1" rowspan="1">
          mapred.fairscheduler.taskselector:
        </td>
        <td colspan="1" rowspan="1">
        An extensibility point that lets you specify a class that determines 
        which task from within a job to launch on a given tracker. This can be 
        used to change either the locality policy (e.g. keep some jobs within 
        a particular rack) or the speculative execution algorithm (select 
        when to launch speculative tasks). The default implementation uses 
        Hadoop's default algorithms from JobInProgress.
        </td>
        
</tr>
      
</table>
</div>
    
<a name="N10151"></a><a name="Administration"></a>
<h2 class="h3"> Administration</h2>
<div class="section">
<p>
      The fair scheduler provides support for administration at runtime 
      through two mechanisms:
    </p>
<ol>
    
<li>
      It is possible to modify pools' allocations 
      and user and pool running job limits at runtime by editing the allocation 
      config file. The scheduler will reload this file 10-15 seconds after it 
      sees that it was modified.
     </li>
     
<li>
     Current jobs, pools, and fair shares  can be examined through the 
     JobTracker's web interface, at  http://&lt;jobtracker URL&gt;/scheduler. 
     On this interface, it is also possible to modify jobs' priorities or 
     move jobs from one pool to another and see the effects on the fair 
     shares (this requires JavaScript).
     </li>
    
</ol>
<p>
      The following fields can be seen for each job on the web interface:
     </p>
<ul>
     
<li>
<em>Submitted</em> - Date and time job was submitted.</li>
     
<li>
<em>JobID, User, Name</em> - Job identifiers as on the standard 
     web UI.</li>
     
<li>
<em>Pool</em> - Current pool of job. Select another value to move job to 
     another pool.</li>
     
<li>
<em>Priority</em> - Current priority. Select another value to change the 
     job's priority</li>
     
<li>
<em>Maps/Reduces Finished</em>: Number of tasks finished / total tasks.</li>
     
<li>
<em>Maps/Reduces Running</em>: Tasks currently running.</li>
     
<li>
<em>Map/Reduce Fair Share</em>: The average number of task slots that this 
     job should have at any given time according to fair sharing. The actual
     number of tasks will go up and down depending on how much compute time
     the job has had, but on average it will get its fair share amount.</li>
     
</ul>
<p>
     In addition, it is possible to turn on an "advanced" view for the web UI,
     by going to http://&lt;jobtracker URL&gt;/scheduler?advanced. This view shows 
     four more columns used for calculations internally:
     </p>
<ul>
     
<li>
<em>Maps/Reduce Weight</em>: Weight of the job in the fair sharing 
     calculations. This depends on priority and potentially also on 
     job size and job age if the <em>sizebasedweight</em> and 
     <em>NewJobWeightBooster</em> are enabled.</li>
     
<li>
<em>Map/Reduce Deficit</em>: The job's scheduling deficit in machine-
     seconds - the amount of resources it should have gotten according to 
     its fair share, minus how many it actually got. Positive deficit means
      the job will be scheduled again in the near future because it needs to 
      catch up to its fair share. The scheduler schedules jobs with higher 
      deficit ahead of others. Please see the Implementation section of 
      this document for details.</li>
     
</ul>
</div>
    
<a name="N101A3"></a><a name="Implementation"></a>
<h2 class="h3">Implementation</h2>
<div class="section">
<p>There are two aspects to implementing fair scheduling: Calculating 
    each job's fair share, and choosing which job to run when a task slot 
    becomes available.</p>
<p>To select jobs to run, the scheduler then keeps track of a 
    "deficit" for each job - the difference between the amount of
     compute time it should have gotten on an ideal scheduler, and the amount 
     of compute time it actually got. This is a measure of how 
     "unfair" we've been to the job. Every few hundred 
     milliseconds, the scheduler updates the deficit of each job by looking
     at how many tasks each job had running during this interval vs. its 
     fair share. Whenever a task slot becomes available, it is assigned to 
     the job with the highest deficit. There is one exception - if there 
     were one or more jobs who were not meeting their pool capacity 
     guarantees, we only choose among these "needy" jobs (based 
     again on their deficit), to ensure that the scheduler meets pool 
     guarantees as soon as possible.</p>
<p>
     The fair shares are calculated by dividing the capacity of the cluster 
     among runnable jobs according to a "weight" for each job. By 
     default the weight is based on priority, with each level of priority 
     having 2x higher weight than the next (for example, VERY_HIGH has 4x the 
     weight of NORMAL). However, weights can also be based on job sizes and ages, 
     as described in the Configuring section. For jobs that are in a pool, 
     fair shares also take into account the minimum guarantee for that pool. 
     This capacity is divided among the jobs in that pool according again to 
     their weights.
     </p>
<p>Finally, when limits on a user's running jobs or a pool's running jobs 
     are in place, we choose which jobs get to run by sorting all jobs in order 
     of priority and then submit time, as in the standard Hadoop scheduler. Any 
     jobs that fall after the user/pool's limit in this ordering are queued up 
     and wait idle until they can be run. During this time, they are ignored 
     from the fair sharing calculations and do not gain or lose deficit (their 
     fair share is set to zero).</p>
</div>
  
</div>
<!--+
    |end content
    +-->
<div class="clearboth">&nbsp;</div>
</div>
<div id="footer">
<!--+
    |start bottomstrip
    +-->
<div class="lastmodified">
<script type="text/javascript"><!--
document.write("Last Published: " + document.lastModified);
//  --></script>
</div>
<div class="copyright">
        Copyright &copy;
         2008 <a href="http://www.apache.org/licenses/">The Apache Software Foundation.</a>
</div>
<!--+
    |end bottomstrip
    +-->
</div>
</body>
</html>
